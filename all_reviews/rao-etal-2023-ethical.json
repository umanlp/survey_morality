{"rao-etal-2023-ethical": {"title": "Ethical Reasoning over Moral Alignment: A Case and Framework for In-Context Ethical Policies in LLMs", "author": "Rao, Abhinav  and\nKhandelwal, Aditi  and\nTanmay, Kumar  and\nAgarwal, Utkarsh  and\nChoudhury, Monojit", "year": "2023", "bibKey": "rao-etal-2023-ethical", "bibtexFile": {}, "surveyFile": {}, "typeApplicationAI": "typeApplicationAI", "typeNotRelevantText": "--", "paperContentLength": "9", "paperTotalLength": "19", "includesAnnotation": "includesAnnotation", "includesLLMPrompt": "includesLLMPrompt", "includesProbing": "includesProbing", "paperMotivationText": "LLMs should be valueneutral and sound ethical reasoners, while ethical alignment should be introduced at the level of applications and/or user interaction.", "paperContributionText": "Development of a framework that integrates moral dilemmas with moral principles pertaining to different foramlisms of normative ethics, and at different levels of abstractions.", "paperResultsText": "Initial experiments with GPTx models shows that while GPT-4 is a nearly perfect ethical reasoner, the models still have bias towards the moral values of Western and English speaking societies.", "theoryOtherText": "--", "theoryOwnText": "--", "theoryNone": "theoryNone", "definition": "definitionYes", "unitDocument": "unitDocument", "langEn": "langEn", "langOther": "--", "dataOther": "dataOther", "dataOtherText": "Moral Dilemmas", "dataDomain": "dataDomainOther", "dataDomainOtherText": "Moral Dilemmas", "resourcesOtherText": "--", "resource": "resourceYes", "annotSizeText": "--", "annotIAATypeText": "--", "annotIAAScoreText": "--", "annotIAAMetricText": "--", "annotSetup": "annotNoAnnot", "annotViews": "annotViewsNotRelevant", "AnnotSchema": "AnnotSchemaNotRelevant", "IAA": "IAANotRelevant", "AnnotErrAnalysis": "AnnotErrAnalysisNotRelevant", "AnnotResourceAvailable": "AnnotResourceAvailableYes", "AnnotResourceAvailableYesURL": "Appendix A of the paper", "experiment": "experimentYes", "expTransformerText": "--", "expLlm": "expLlm", "expLlmText": "GPT-3.5-turbo (ChatGPT), GPT-4, GPT-3 (davinci), text-davinci-002, text-davinci-003.", "semiMLText": "--", "unsuperMLText": "--", "expOtherText": "--", "ExpErrAnalysis": "ExpErrAnalysisRudimentary", "replicTrainTest": "replicTrainTestNotRelevant", "replicGold": "replicGoldClear", "analysis": "analysisYes", "analysisField": "analysisFieldPolitics", "analysisFieldOtherText": "--", "analysisType": "analysisExplore", "dataAvail": "dataAvailYes", "dataYesUrlText": "The dataset is very small (4 moral dilemmas and prompts) so it fits into the Appendix", "dataYesCommentText": "--", "dataPartlyUrlText": "--", "replicPreproc": "replicPreprocClear", "replicCodeText": "--", "replicCode": "replicCodeNotRelevant", "validationAnnotation": "validationAnnotation", "validationTriangulation": "validationTriangulation", "validationOtherText": "--"}}