{"kiehne-etal-2022-contextualizing": {"title": "Contextualizing Language Models for Norms Diverging from Social Majority", "author": "Kiehne, Niklas  and\nKroll, Hermann  and\nBalke, Wolf-Tilo", "year": "2022", "bibKey": "kiehne-etal-2022-contextualizing", "bibtexFile": {}, "surveyFile": {}, "typeResource": "typeResource", "typeExperiment": "typeExperiment", "typeApplicationAI": "typeApplicationAI", "typeNotRelevantText": "--", "paperContentLength": "9", "paperTotalLength": "14", "includesSupervised": "includesSupervised", "includesLogicBased": "includesLogicBased", "paperMotivationText": "The goal of this paper is to understand how well pre-trained language models can be adapted to new norms not contained in the original training data.", "paperContributionText": "The authors introduce a method based on deontic logic to adapt pre-trained language models to individual norms by de-biasing training sets. They conduct several experiments with language models on these newly derived datasets.", "paperResultsText": "Norms that are left out in a fine-tuning dataset are severly misrepresented in fine-tuned models. Pre-training is essential to adapt models to highly conflicting norms.", "theoryOtherText": "--", "theoryOwnText": "--", "theoryNone": "theoryNone", "definition": "definitionNo", "unitSegment": "unitSegment", "goalAI": "goalAI", "langEn": "langEn", "langOther": "--", "dataOther": "dataOther", "dataOtherText": "moral judgement-action-norm triplets", "dataDomain": "dataDomainOther", "dataDomainOtherText": "morally relevant topics", "resourcesSocialChemistry": "resourcesSocialChemistry", "resourcesMoralStories": "resourcesMoralStories", "resourcesOtherText": "--", "resource": "resourceYes", "annotSizeText": "unknown", "annotSetup": "annotNoAnnot", "annotViews": "annotViewsNotRelevant", "AnnotSchema": "AnnotSchemaNotRelevant", "annotIAATypeText": "--", "annotIAAScoreText": "--", "annotIAAMetricText": "--", "IAA": "IAANotRelevant", "AnnotErrAnalysis": "AnnotErrAnalysisNotRelevant", "AnnotResourceAvailable": "AnnotResourceAvailableYes", "AnnotResourceAvailableYesURL": "https://github.com/nikrruun/contrastive_moral_stories", "AnnotResourceAvailablePartlyURL": "--", "experiment": "experimentYes", "expTransformers": "expTransformers", "expTransformerText": "T5, BART, DistillBERT, BERT, RoBERTa, AlBERT, GPT-Neo", "logicML": "logicML", "expLlmText": "--", "semiMLText": "--", "unsuperMLText": "--", "expOtherText": "--", "ExpErrAnalysis": "ExpErrAnalysisYes", "replicTrainTest": "replicTrainTestYes", "replicGold": "replicGoldNotRelevant", "analysisFieldOtherText": "--", "analysis": "analysisNo", "dataAvail": "dataAvailYes", "dataYesUrlText": "https://huggingface.co/datasets/demelin/moral_stories", "dataYesCommentText": "--", "dataPartlyUrlText": "--", "replicPreproc": "replicPreprocClear", "replicCode": "replicCodeYes", "replicCodeText": "https://github.com/nikrruun/contrastive_moral_stories", "validationAnnotation": "validationAnnotation", "validationOtherText": "--"}}