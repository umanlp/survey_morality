{"pyatkin-etal-2023-clarifydelphi": {"title": "ClarifyDelphi: Reinforced Clarification Questions with Defeasibility Rewards for Social and Moral Situations", "author": "Pyatkin, Valentina  and\nHwang, Jena D.  and\nSrikumar, Vivek  and\nLu, Ximing  and\nJiang, Liwei  and\nChoi, Yejin  and\nBhagavatula, Chandra", "year": "2023", "bibKey": "pyatkin-etal-2023-clarifydelphi", "bibtexFile": {}, "surveyFile": {}, "typeResource": "typeResource", "typeExperiment": "typeExperiment", "typeApplicationAI": "typeApplicationAI", "typeNotRelevantText": "--", "paperContentLength": "9", "paperTotalLength": "19", "includesOntology": "includesOntology", "includesSupervised": "includesSupervised", "includesProbing": "includesProbing", "paperMotivationText": "Context is everything, even in commonsense moral reasoning. Changing contexts can flip the moral judgment of an action; Lying to a friend is wrong in general, but may be morally acceptable if it is intended to protect their life.", "paperContributionText": "The paper presents CLARIFYDELPHI, an interactive system (reinforcement learning framework) that learns to ask clarification questions (e.g., \u201cwhy did you lie to your friend?\u201d) in order to elicit additional salient contexts of a social or moral situation.", "paperResultsText": "Human evaluation demonstrates that the system generates more relevant, informative and defeasible questions compared to competitive baselines", "theoryOtherText": "--", "theoryOwnText": "--", "theoryNone": "theoryNone", "definition": "definitionVague", "unitDocument": "unitDocument", "goalAI": "goalAI", "langEn": "langEn", "langOther": "--", "dataOther": "dataOther", "dataOtherText": "Moral situations", "dataDomain": "dataDomainOther", "dataDomainOtherText": "Mixed moral situations", "resourcesSocialChemistry": "resourcesSocialChemistry", "resourcesOther": "resourcesOther", "resourcesOtherText": "COMMONSENSE NORM BANK (Jiang et al., 2022)", "resource": "resourceYes", "annotSizeText": "clarification questions for 6425 situations", "annotSetup": "annotCrowd", "annotViews": "annotViewsYes", "AnnotSchema": "AnnotSchemaYes", "AnnotSchemaLen": "AnnotSchemaLen2", "annotIAATypeText": "--", "annotIAAScoreText": "--", "annotIAAMetricText": "--", "IAA": "IAANo", "AnnotErrAnalysis": "AnnotErrAnalysisRudimentary", "AnnotResourceAvailable": "AnnotResourceAvailableYes", "AnnotResourceAvailableYesURL": "https://github.com/allenai/clarifydelphi/tree/main/Data", "AnnotResourceAvailablePartlyURL": "--", "experiment": "experimentYes", "expTransformerText": "--", "expReinforcement": "expReinforcement", "expLlmText": "--", "semiMLText": "--", "unsuperMLText": "--", "expOtherText": "--", "ExpErrAnalysis": "ExpErrAnalysisRudimentary", "replicTrainTest": "replicTrainTestYes", "replicGold": "replicGoldClear", "analysis": "analysisYes", "analysisField": "analysisFieldMedia", "analysisFieldOtherText": "--", "analysisType": "analysisRQ", "dataAvail": "dataAvailYes", "dataYesUrlText": "https://github.com/allenai/clarifydelphi/tree/main/Data", "dataYesCommentText": "--", "dataPartlyUrlText": "--", "replicPreproc": "replicPreprocClear", "replicCode": "replicCodeYes", "replicCodeText": "https://github.com/allenai/clarifydelphi/tree/main/Code", "validationTriangulation": "validationTriangulation", "validationOtherText": "--"}}