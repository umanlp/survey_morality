{"alshomary-etal-2022-moral": {"title": "The Moral Debater: A Study on the Computational Generation of Morally Framed Arguments", "author": "Alshomary, Milad  and\nEl Baff, Roxanne  and\nGurcke, Timon  and\nWachsmuth, Henning", "year": "2022", "bibKey": "alshomary-etal-2022-moral", "bibtexFile": {}, "surveyFile": {}, "typeResource": "typeResource", "typeExperiment": "typeExperiment", "typeNotRelevantText": "--", "paperContentLength": "9", "paperTotalLength": "16", "includesAnnotation": "includesAnnotation", "includesSupervised": "includesSupervised", "paperMotivationText": "An audience's beliefs and morals are indicators of how likely they will be affected by an argument. This information can be used to bring disagreeing parties towards agreement.", "paperContributionText": "They propose a model to automatically generate morally framed arguments. One component of this architecture is a moral value classifier that they train on their own distantly supervised training set. This training set was created by mapping argumentative texts from an existing corpus (Schiller et al. 2020) to moral foundations, using the lexicon of Hulpus et al. (2020). They then evaluate the impact of the automatically generated arguments in a user study.", "paperResultsText": "When prior beliefs are challenged, an audience becomes more affected by morally framed arguments. Generally, arguments targeting the moral foundations of care and fairness are more effective than others.", "theoryMFT": "theoryMFT", "numMF": "numMF5", "theoryOtherText": "--", "theoryOwnText": "--", "definition": "definitionYes", "unitSentence": "unitSentence", "goalPerson": "goalPerson", "goalComparison": "goalComparison", "langEn": "langEn", "langOther": "--", "dataSM": "dataSM", "dataSMReddit": "dataSMReddit", "dataOther": "dataOther", "dataOtherText": "debates", "dataDomain": "dataDomainOther", "dataDomainOtherText": "varied (online debate platforms)", "resourcesOther": "resourcesOther", "resourcesOtherText": "Reddit argumentative texts (Schiller et al. 2020), Exploring morality in argumentation (Kobbe et al. 2020), Project Debater", "resource": "resourceYes", "annotSizeText": "230k texts, 60 arguments", "annotSetup": "annotMixed", "annotViews": "annotViewsYes", "AnnotSchema": "AnnotSchemaYes", "AnnotSchemaLen": "AnnotSchemaLen1", "IAA": "IAAYes", "annotIAATypeText": "moral values in argumentative texts, arguments effectiveness judgements", "annotIAAScoreText": "0.32, 0.29", "annotIAAMetricText": "Cohen's kappa, Kendall's W", "AnnotErrAnalysis": "AnnotErrAnalysisNo", "AnnotResourceAvailableYesURL": "--", "AnnotResourceAvailable": "AnnotResourceAvailablePartly", "AnnotResourceAvailablePartlyURL": "https://github.com/webis-de/acl22-moral-debater-a-study-on-the-computational-generation-of-morally-framed-arguments", "experiment": "experimentYes", "expTransformers": "expTransformers", "expTransformerText": "BERT-base", "expLlmText": "--", "semiMLText": "--", "unsuperMLText": "--", "expOtherText": "--", "ExpErrAnalysis": "ExpErrAnalysisNo", "replicTrainTest": "replicTrainTestYes", "replicGold": "replicGoldClear", "analysisField": "analysisFieldPolitics", "analysisFieldOtherText": "--", "analysis": "analysisNo", "dataAvail": "dataAvailYes", "dataYesUrlText": "https://github.com/UKPLab/controlled-argument-generation, https://github.com/dwslab/Morality-in-Arguments", "dataYesCommentText": "--", "dataPartlyUrlText": "--", "replicPreproc": "replicPreprocClear", "replicCode": "replicCodeYes", "replicCodeText": "https://github.com/webis-de/acl22-moral-debater-a-study-on-the-computational-generation-of-morally-framed-arguments", "validationAnnotation": "validationAnnotation", "validationOtherText": "--"}}