{"h\u00e4mmerl2022multilingual": {"title": "Do Multilingual Language Models Capture Differing Moral Norms?", "author": "Katharina H\u00e4mmerl and Bj\u00f6rn Deiseroth and Patrick Schramowski and Jind\u0159ich Libovick\u00fd and Alexander Fraser and Kristian Kersting", "year": "2022", "bibKey": "h\u00e4mmerl2022multilingual", "bibtexFile": {}, "surveyFile": {}, "typeApplicationAI": "typeApplicationAI", "typeNotRelevantText": "--", "paperContentLength": "3", "paperTotalLength": "5", "includesLLMPrompt": "includesLLMPrompt", "includesProbing": "includesProbing", "paperMotivationText": "Massively multilingual sentence representations are trained on large corpora of uncurated data, with a very imbalanced proportion of lan- guages included in the training. This may cause the models to grasp cultural values including moral judgments from the high-resource lan- guages and impose them on the low-resource languages. The lack of data in certain languages can also lead to developing random and thus poten- tially harmful beliefs. Both these issues can negatively influence zero-shot cross-lingual model transfer and potentially lead to harmful outcomes.", "paperContributionText": "The authors detect and quantify these issues by comparing different models in different languages and develop methods for improving undesirable properties of the models.", "paperResultsText": "Initial experiments using the multilingual model XLM-R show that indeed multilingual LMs capture moral norms, even with potentially higher human-agreement than mono- lingual ones. However, it is not yet clear to what extent these moral norms differ between languages.", "theoryOtherText": "--", "theoryOwnText": "--", "theoryNone": "theoryNone", "definition": "definitionNo", "unitSentence": "unitSentence", "unitToken": "unitToken", "goalAI": "goalAI", "langEn": "langEn", "langOther": "--", "dataOther": "dataOther", "dataOtherText": "Mixed moral statements", "dataDomain": "dataDomainOther", "dataDomainOtherText": "Mixed", "resourcesEthics": "resourcesEthics", "resourcesOtherText": "--", "annotSizeText": "--", "annotIAATypeText": "--", "annotIAAScoreText": "--", "annotIAAMetricText": "--", "AnnotResourceAvailableYesURL": "--", "AnnotResourceAvailablePartlyURL": "--", "resource": "resourceNo", "experiment": "experimentYes", "expTransformerText": "--", "expLlm": "expLlm", "expLlmText": "BERT, XLM", "semiMLText": "--", "unsuperMLText": "--", "expOtherText": "--", "ExpErrAnalysis": "ExpErrAnalysisNo", "replicTrainTest": "replicTrainTestNotRelevant", "replicGold": "replicGoldNotRelevant", "analysisFieldOtherText": "--", "analysis": "analysisNo", "dataYesUrlText": "--", "dataYesCommentText": "--", "dataPartlyUrlText": "--", "dataAvail": "dataAvailNoInfo", "replicPreproc": "replicPreprocUnclear", "replicCodeText": "--", "replicCode": "replicCodeNotRelevant", "validationAnnotation": "validationAnnotation", "validationOtherText": "--"}}